
## Methods  {.page_break_before}

A visual overview of the computational methods is provided in Figure @fig:workflow and is available as a snakemake pipeline (https://github.com/ktmeaton/plague-phylogeography/).

![
Computational methods workflow.
](https://rawcdn.githack.com/ktmeaton/plague-phylogeography-projects/6d9ab2e/main/report/workflow.png){#fig:workflow}

### Data Collection {.page_break_before}

*Y. pestis* genome sequencing projects were retrieved from the NCBI databases using NCBImeta [@eaton2020NCBImetaEfficientComprehensive]. 1657 projects were identified and comprised three genomic types:

- 586 modern assembled
- 184 ancient unassembled
- 887 modern unassembled

The 887 modern unassembled genomes were excluded from this project, as the wide variety of laboratory methods and sequencing strategies precluded a standardized workflow. In contrast, the 184 ancient unassembled genomes were retained given the relatively standardized, albeit specialized, laboratory procedures required to process ancient tissues. Future work will investigate computationally efficient methods for integrating more diverse datasets.

Collection location, collection date, and collection host metadata were curated by cross-referencing the original publications. Collection location was transformed to latitude and longitude coordinates using GeoPy [@esmukov2020GeoPyPythonClient]  and the Nominatim API [@hoffman2020NominatimToolSearch] for OpenStreetMap  [@openstreetmapcontributors2017PlanetDumpRetrieved]. Coordinates were standardized at a sub-country resolution, taking the centroid of the parent province/state. Collection dates were standardized according to their year, and recording uncertainty arising from missing data and radiocarbon estimates. Collection host was the most diverse field with regards to precision, ranging from colloquial nomenclature (*"rat"*) to a genus species taxonomy (*"Meriones libycus"*). For the purposes of this study, collection host was recorded as *Human*, *Non-Human*, or *Not Available*, given the inability to differentiate non-human mammalian hosts.

Genomes were removed if no associated date or location information could be identified in the literature, or if there was documented evidence of laboratory manipulation.

Two additional datasets were required for downstream analyses. First, *Y. pestis* strain CO92 (GCA_000009065.1) was used as the reference genome for sequence alignment and annotation. Second, *Yersinia pseudotuberculosis* strains NCTC10275 (GCA_900637475.1) and IP32953 (GCA_000834295.1) served as an outgroup to root the maximum likelihood phylogeny.

### Alignment

Modern assembled genomes were aligned to the reference genome using Snippy, a pipeline for core genome alignments [@seemann2020SnippyRapidHaploid]. Modern genomes were removed if the number of sites covered at a minimum depth of 10X was less than 70% of the reference genome.

Ancient unassembled genomes were downloaded from the SRA database in FASTQ format using the SRA Toolkit [@NCBI2021SRAToolkit]. Pre-processing and alignment to the reference genome was performed using the nf-core/eager pipeline, a reproducible workflow for ancient genome reconstruction [@yates2021ReproduciblePortableEfficient]. Ancient genomes were removed if the number of sites covered at a minimum depth of 3X was less than 70% of the reference genome. It is a typical approach to relax coverage thresholds for ancient genomes relative to their modern counterparts [@cite]. The threshold chosen here is commonly used, and aims to strike a balance between variant confidence and sample representation [@cite].

A multiple sequence alignment was constructed using the Snippy Core module of the Snippy pipeline [@seemann2020SnippyRapidHaploid]. The output alignment was filtered to only include chromosomal variants and to exclude sites that had more than 5% missing data.

### Modified Datasets

To investigate the influence of between-clade variation in substitution rates, the multiple alignment was separated into the major clades of *Y. pestis*, which is referred to as the *clade* dataset. Clade labeling was derived from the five-branch population structure accompanied by a biovar abbreviation [@cui2013HistoricalVariationsMutation]. Only one modification was made, in that the subclade associated with the Plague of Justinian (0.ANT4) was considered to be a distinct clade from its parent (0.ANT) due to its geographic, temporal, and ecological uniqueness.

To improve the performance and convergence of Bayesian analysis, a subsampled dataset was constructed and is referred to as the *reduced* dataset. Clades that contained multiple samples drawn from the same geographic location and the same time period were reduced to one representative sample. The sample with the shortest terminal branch length was prioritized, to diminish the influence of uniquely derived mutations on the estimated substitution rate. An interval of 25 years was identified as striking an optimal balance, resulting in 191 representative samples.

### Phylogenetics

Model selection was performed using Modelfinder which identified the K3Pu+F+I model as the optimal choice based on the Bayesian Information Criterion (BIC) [@kalyaanamoorthy2017ModelFinderFastModel]. A maximum-likelihood phylogeny was then estimated across 10 independent runs of IQTREE [@minh2020IQTREENewModels]. Branch support was evaluated using 1000 iterations of the ultrafast bootstrap approximation, with a threshold of 95% required for strong support [@hoang2018UFBoot2ImprovingUltrafast].

### Phylodynamics

To explore the degree of temporal signal present in the data, two categories of tests were performed . The first was a root-to-tip (RTT) regression on collection date using the python package ```statsmodels``` [@seabold2010StatsmodelsEconometricStatistical]. Given the relative simplicity of a regression model, the *full* dataset of 601 genomes was used. For the second test of temporal signal, a Bayesian Evaluation of Temporal Signal (BETS) was conducted. As the complexity of Bayesian modeling is computationally intensive, the *reduced* dataset (N=191) was used.

> **Kat's Notes**:<br>
> - I will need Sebastian and Leo's input here to write the BEAST methods section.

### Public Resource

The maximum likelihood and Bayesian phylogenetic trees were uploaded to the Nextstrain visualization platform at https://nextstrain.org/community/ktmeaton/plague-phylogeography-projects@main. All curated metadata is available for download via Nextstrain, Github, and Zenodo.

> **Kat's Notes**:<br>
> - I'll need to prepare stable and archived hosting links before submission.